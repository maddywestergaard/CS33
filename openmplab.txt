First, I tested to see how fast the program is without OpenMP:

$ make seq
$ ./seq
FUNC TIME : 0.740929
TOTAL TIME : 2.538777

Then I used gprof to see the bottlenecks of the program

$ make seq GPROF=1
$ ./seq
$ gprof seq

Each sample counts as 0.01 seconds.
  %   cumulative   self              self     total           
 time   seconds   seconds    calls  ms/call  ms/call  name    
 72.05      0.59     0.59       15    39.39    40.78  func1
 13.43      0.70     0.11  5177344     0.00     0.00  rand2
  3.66      0.73     0.03        1    30.04   119.27  addSeed
  2.44      0.75     0.02   491520     0.00     0.00  findIndexBin
  2.44      0.77     0.02        2    10.01    10.01  init
  2.44      0.79     0.02        1    20.03    20.03  imdilateDisk
  2.44      0.81     0.02                             filter
  1.22      0.82     0.01       15     0.67     0.67  func4
  0.00      0.82     0.00   983042     0.00     0.00  round
  0.00      0.82     0.00       16     0.00     0.00  dilateMatrix
  0.00      0.82     0.00       15     0.00     0.00  func2
  0.00      0.82     0.00       15     0.00     0.00  func3
  0.00      0.82     0.00       15     0.00     1.34  func5
  0.00      0.82     0.00       15     0.00     0.00  rand1
  0.00      0.82     0.00        2     0.00     0.00  get_time
  0.00      0.82     0.00        1     0.00     0.00  elapsed_time
  0.00      0.82     0.00        1     0.00     0.00  fillMatrix
  0.00      0.82     0.00        1     0.00     0.00  func0
  0.00      0.82     0.00        1     0.00     0.00  getNeighbors

From this table that it gives, it is clear that func1 is the greatest
bottleneck, taking up 72% of the time.

Then I did some research on OpenMP and gathered all the information I
needed to optimize the program and use parallelism.

I added :
#pragma omp parallel for num_threads(20)
before every for loop, and for for loops that used outside variables
defined outside of the scope of the loop, I added the private(var) at the end
of that line.
and for for loops that changed the values of variables declared outside of the
loop, I used reduction(+:var) at the end of that line.

Also, I added the num_threads(20) to make it faster and help the parallelization

After all of these changes, I tested to see the speed up:

$ make omp
$ ./omp
FUNC TIME : 0.058665
TOTAL TIME : 1.918959

$ make omp GPROF=1
$ ./omp
$ gprof omp
Flat profile:

Each sample counts as 0.01 seconds.
  %   cumulative   self              self     total           
 time   seconds   seconds    calls  ms/call  ms/call  name    
 67.24      0.45     0.45       31    14.53    15.87  filter
 16.44      0.56     0.11  4244790     0.00     0.00  rand2
  5.98      0.60     0.04    21599     0.00     0.00  findIndexBin
  4.48      0.63     0.03        1    30.03   138.84  addSeed
  2.99      0.65     0.02                             sequence
  1.49      0.66     0.01        2     5.01     5.01  init
  1.49      0.67     0.01        1    10.01    10.01  imdilateDisk
  0.00      0.67     0.00    89160     0.00     0.00  round
  0.00      0.67     0.00       16     0.00     0.00  dilateMatrix
  0.00      0.67     0.00       15     0.00     0.00  func1
  0.00      0.67     0.00       15     0.00     0.00  func2
  0.00      0.67     0.00       15     0.00     0.00  func3
  0.00      0.67     0.00       15     0.00     0.00  func4
  0.00      0.67     0.00       15     0.00     0.00  func5
  0.00      0.67     0.00       15     0.00     0.00  rand1
  0.00      0.67     0.00        2     0.00     0.00  get_time
  0.00      0.67     0.00        1     0.00     0.00  elapsed_time
  0.00      0.67     0.00        1     0.00     0.00  fillMatrix
  0.00      0.67     0.00        1     0.00     0.00  func0
  0.00      0.67     0.00        1     0.00     0.00  getNeighbors

Now, none of the funcs are bottlenecks!

Then I did make checkmem to make sure there was no unfreed memory.

$ make omp MTRACE=1
$ ./omp
$ make checkmem
mtrace filter mtrace.out || true

Memory not freed:
-----------------
           Address     Size     Caller
0x00000000011ee0a0     0xd0  at 0x7f582fa197f9
0x00000000011ee180   0x1620  at 0x7f582fa197f9
0x00000000011ef7b0     0xc0  at 0x7f582fa197f9
0x00000000011ef880     0xa8  at 0x7f582fa19849
0x00000000011ef930    0x240  at 0x7f582ff4a885
0x00000000011efb80    0x240  at 0x7f582ff4a885
0x00000000011efdd0    0x240  at 0x7f582ff4a885
0x00000000011f0020    0x240  at 0x7f582ff4a885
0x00000000011f0270    0x240  at 0x7f582ff4a885
0x00000000011f04c0    0x240  at 0x7f582ff4a885
0x00000000011f0710    0x240  at 0x7f582ff4a885
0x00000000011f0960    0x240  at 0x7f582ff4a885
0x00000000011f0bb0    0x240  at 0x7f582ff4a885
0x00000000011f0e00    0x240  at 0x7f582ff4a885
0x00000000011f1050    0x240  at 0x7f582ff4a885
0x00000000011f12a0    0x240  at 0x7f582ff4a885
0x00000000011f14f0    0x240  at 0x7f582ff4a885
0x00000000011f1740    0x240  at 0x7f582ff4a885
0x00000000011f1990    0x240  at 0x7f582ff4a885
0x00000000011f1be0    0x240  at 0x7f582ff4a885
0x00000000011f1e30    0x240  at 0x7f582ff4a885
0x00000000011f2080    0x240  at 0x7f582ff4a885
0x00000000011f22d0    0x240  at 0x7f582ff4a885

There is a lot of unfreed memory, but it turns out that OpenMP has bugs
and this is no fault of mine

Lastly, I ran

$ make check

to make sure that the output was correct, and it was.

The original version took about 0.79 seconds, and the sped up version took
about 0.06 seconds. 

This means I attained approximately 13x speed up
